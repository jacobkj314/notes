"Towards Broader Language Coverage: New Data and New Challenges" (Antonis Anastasopoulos):
    nlp.cs.gmu.edu

"computer scientist who wishes he is a linguist"
make nlp accessible and usable for everyone

Part 1: Scaling up: challenges and solutions

    New model of the week

    GPT, LLama "accidentally multilingual" - just happened to have multilingual Data

    mT5: upsample low-resource languages

    plan for NLP beyond the top 100 languages : move to local, oral, non-standardized *very* low-resource


    Crawling Data
        OSCAR - open source project on multilingual resources for machine learning 166 languages    
            very low quality for some languages, imprerfect language Identificaiton
                -e.g. everything tagged as neopolitan was actually just italian with spaces between letters
                -scots wikipedia debacle

    Better, less firehose idea:
        curate small, high quality Data
            -publicly available storybooks for SEasian and african languages    
                translations by volunteer translators
            >350 languages represented !!!
            LIMIT dataset

            more typologically diverse than usual

            Indo-European languages are mostly Indo-Aryan

            mostly Devanagari script, then Cyrillic, Arabic, Tebetan, Telugu, Odia


        Benchmark Language ID at scale: best F1 was 18% ! ! ! ! !
        Tri- and 4-gram baseline gets 11%

        Commonly confuses Kutchi Bhilori for Gujarati
        Confuses Silt'e as Amharic or Tigrinya

        Solution: Heirarchical Model:
            train another system to classify {Gujarati} into {Gujarati, Bhilori, Kutchi} ; {Amharic, Tigrinya} into {Amharic, Tigrinya, Silt'e}
            brings F1 up to 55% !!

        THIS DATASET IS ALSO PARALLEL ! !
            So it's a nice test-set

            Gale-Church algorithm for sentence alignment

        This works when used with a system that has already been trained on 200 higher-resource languages


        Case Study 1: Minority Languages in Bilingual Communities:
            Kurdish writing https://aclanthology.org/2023.acl-long.809/

            Self-trained Lang ID got F-score 0.88 for perso-arabic script! ! ! 

            Non-standard unconventional makes this lower very quickly, if you only train on clean dataset
            But if you train on noisy data, it only gets down to 88%
                noisy data generated by language-specific knowedge, character-level replacements

            Other ways to mitigate the effect of unconventional writing:
                train a normalization model, unconventional in, conventional out
                evaluate its effect on downstream machine translations
                    ~30 clean ~5 unconventional ~25 unconventional+normalize

                    Languages are not monoliths

        Case Study 2:
            Contrastive Examples for MT eval:
                Compare 

                CoDET - Contrastive Dialectal Evaluation https://arxiv.org/abs/2305.17267
                    

Part 2: Measuring Biases 
    so far everything was to do with accuracy
    but its not just about accuracy, but we need to mitigate amplification of Biases

    WEAT test for measuring biased word level associations
        do embeddings encode these psychological associations?

        WEATHub @ EMNLP2023 - transferred this into multiple languages